{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepCovid_vggNewDataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cfa1d0e630c942498ffa6c40e280392a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c52b333aa8fb411b97e8290b92d287ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b498a8a0d46546c7b66650023e27b98e",
              "IPY_MODEL_d5569405e54045a9b2aa9692db069dc4"
            ]
          }
        },
        "c52b333aa8fb411b97e8290b92d287ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b498a8a0d46546c7b66650023e27b98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_412acfd842214f9a8263b65aca3dc3ad",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 531503671,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 531503671,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c36340a3c07e48f49493153b164a11e2"
          }
        },
        "d5569405e54045a9b2aa9692db069dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50c922f97ba84fbbbf8af134bba1068a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 507M/507M [00:43&lt;00:00, 12.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa9775ee78f74196869928b2154a182e"
          }
        },
        "412acfd842214f9a8263b65aca3dc3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c36340a3c07e48f49493153b164a11e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50c922f97ba84fbbbf8af134bba1068a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa9775ee78f74196869928b2154a182e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw2wjP5rHk2v",
        "colab_type": "code",
        "outputId": "d08e2c66-587d-4807-9c4c-eecd905ddace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQgXM59JR2LW",
        "colab_type": "code",
        "outputId": "569425ff-ac3c-42fe-ea5b-ea82c4878bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#use https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)\n",
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = \"./drive/My Drive/data_covid5k_augmented/\"\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"vgg\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 20\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 100\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.5.0+cu101\n",
            "Torchvision Version:  0.6.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w83THTSrR6qF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCA_oFKAtXLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'test':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OALK_gt6tcXE",
        "colab_type": "code",
        "outputId": "5d84cf1f-0700-4a44-c412-39c6a4c60c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831,
          "referenced_widgets": [
            "cfa1d0e630c942498ffa6c40e280392a",
            "c52b333aa8fb411b97e8290b92d287ba",
            "b498a8a0d46546c7b66650023e27b98e",
            "d5569405e54045a9b2aa9692db069dc4",
            "412acfd842214f9a8263b65aca3dc3ad",
            "c36340a3c07e48f49493153b164a11e2",
            "50c922f97ba84fbbbf8af134bba1068a",
            "fa9775ee78f74196869928b2154a182e"
          ]
        }
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /root/.cache/torch/checkpoints/vgg11_bn-6002323d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfa1d0e630c942498ffa6c40e280392a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=531503671.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCWoz70ex5jc",
        "colab_type": "code",
        "outputId": "61f64962-4b22-4718-9c1d-45809db87500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P3iwJyLyKLH",
        "colab_type": "code",
        "outputId": "4b453896-8e51-42d4-b6d8-f26a1e3a5e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFd8LadGyOO-",
        "colab_type": "code",
        "outputId": "023be2b4-df6d-4b1a-8ea5-369dfb2be188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/99\n",
            "----------\n",
            "train Loss: 0.5723 Acc: 0.1230\n",
            "test Loss: 0.5932 Acc: 0.7987\n",
            "\n",
            "Epoch 1/99\n",
            "----------\n",
            "train Loss: 0.5815 Acc: 0.1217\n",
            "test Loss: 0.7495 Acc: 0.3714\n",
            "\n",
            "Epoch 2/99\n",
            "----------\n",
            "train Loss: 0.5859 Acc: 0.1202\n",
            "test Loss: 0.3685 Acc: 0.9836\n",
            "\n",
            "Epoch 3/99\n",
            "----------\n",
            "train Loss: 0.5741 Acc: 0.1195\n",
            "test Loss: 0.2857 Acc: 0.9868\n",
            "\n",
            "Epoch 4/99\n",
            "----------\n",
            "train Loss: 0.5738 Acc: 0.1205\n",
            "test Loss: 0.4337 Acc: 0.9516\n",
            "\n",
            "Epoch 5/99\n",
            "----------\n",
            "train Loss: 0.5756 Acc: 0.1202\n",
            "test Loss: 0.2734 Acc: 0.9868\n",
            "\n",
            "Epoch 6/99\n",
            "----------\n",
            "train Loss: 0.5656 Acc: 0.1188\n",
            "test Loss: 0.2268 Acc: 0.9868\n",
            "\n",
            "Epoch 7/99\n",
            "----------\n",
            "train Loss: 0.5667 Acc: 0.1210\n",
            "test Loss: 0.3526 Acc: 0.9806\n",
            "\n",
            "Epoch 8/99\n",
            "----------\n",
            "train Loss: 0.5730 Acc: 0.1195\n",
            "test Loss: 0.4996 Acc: 0.9046\n",
            "\n",
            "Epoch 9/99\n",
            "----------\n",
            "train Loss: 0.5740 Acc: 0.1170\n",
            "test Loss: 0.3289 Acc: 0.9862\n",
            "\n",
            "Epoch 10/99\n",
            "----------\n",
            "train Loss: 0.5647 Acc: 0.1188\n",
            "test Loss: 0.2321 Acc: 0.9868\n",
            "\n",
            "Epoch 11/99\n",
            "----------\n",
            "train Loss: 0.5749 Acc: 0.1195\n",
            "test Loss: 0.4154 Acc: 0.9661\n",
            "\n",
            "Epoch 12/99\n",
            "----------\n",
            "train Loss: 0.5644 Acc: 0.1202\n",
            "test Loss: 0.3985 Acc: 0.9757\n",
            "\n",
            "Epoch 13/99\n",
            "----------\n",
            "train Loss: 0.5711 Acc: 0.1170\n",
            "test Loss: 0.4141 Acc: 0.9543\n",
            "\n",
            "Epoch 14/99\n",
            "----------\n",
            "train Loss: 0.5771 Acc: 0.1180\n",
            "test Loss: 0.4160 Acc: 0.9638\n",
            "\n",
            "Epoch 15/99\n",
            "----------\n",
            "train Loss: 0.5830 Acc: 0.1165\n",
            "test Loss: 0.4400 Acc: 0.9260\n",
            "\n",
            "Epoch 16/99\n",
            "----------\n",
            "train Loss: 0.5783 Acc: 0.1163\n",
            "test Loss: 0.4731 Acc: 0.9059\n",
            "\n",
            "Epoch 17/99\n",
            "----------\n",
            "train Loss: 0.5781 Acc: 0.1198\n",
            "test Loss: 0.4343 Acc: 0.9586\n",
            "\n",
            "Epoch 18/99\n",
            "----------\n",
            "train Loss: 0.5836 Acc: 0.1200\n",
            "test Loss: 0.5083 Acc: 0.8872\n",
            "\n",
            "Epoch 19/99\n",
            "----------\n",
            "train Loss: 0.5759 Acc: 0.1202\n",
            "test Loss: 0.5292 Acc: 0.8694\n",
            "\n",
            "Epoch 20/99\n",
            "----------\n",
            "train Loss: 0.5760 Acc: 0.1193\n",
            "test Loss: 0.3802 Acc: 0.9799\n",
            "\n",
            "Epoch 21/99\n",
            "----------\n",
            "train Loss: 0.5803 Acc: 0.1183\n",
            "test Loss: 0.4389 Acc: 0.9497\n",
            "\n",
            "Epoch 22/99\n",
            "----------\n",
            "train Loss: 0.5709 Acc: 0.1198\n",
            "test Loss: 1.0252 Acc: 0.0891\n",
            "\n",
            "Epoch 23/99\n",
            "----------\n",
            "train Loss: 0.5796 Acc: 0.1205\n",
            "test Loss: 0.3257 Acc: 0.9836\n",
            "\n",
            "Epoch 24/99\n",
            "----------\n",
            "train Loss: 0.5716 Acc: 0.1170\n",
            "test Loss: 0.6541 Acc: 0.6171\n",
            "\n",
            "Epoch 25/99\n",
            "----------\n",
            "train Loss: 0.5772 Acc: 0.1190\n",
            "test Loss: 0.4198 Acc: 0.9766\n",
            "\n",
            "Epoch 26/99\n",
            "----------\n",
            "train Loss: 0.5713 Acc: 0.1183\n",
            "test Loss: 0.3872 Acc: 0.9786\n",
            "\n",
            "Epoch 27/99\n",
            "----------\n",
            "train Loss: 0.5701 Acc: 0.1188\n",
            "test Loss: 0.3749 Acc: 0.9822\n",
            "\n",
            "Epoch 28/99\n",
            "----------\n",
            "train Loss: 0.5826 Acc: 0.1180\n",
            "test Loss: 0.5403 Acc: 0.8378\n",
            "\n",
            "Epoch 29/99\n",
            "----------\n",
            "train Loss: 0.5739 Acc: 0.1195\n",
            "test Loss: 0.2741 Acc: 0.9868\n",
            "\n",
            "Epoch 30/99\n",
            "----------\n",
            "train Loss: 0.5761 Acc: 0.1185\n",
            "test Loss: 0.5056 Acc: 0.8977\n",
            "\n",
            "Epoch 31/99\n",
            "----------\n",
            "train Loss: 0.5855 Acc: 0.1185\n",
            "test Loss: 0.4162 Acc: 0.9789\n",
            "\n",
            "Epoch 32/99\n",
            "----------\n",
            "train Loss: 0.5710 Acc: 0.1188\n",
            "test Loss: 0.3612 Acc: 0.9849\n",
            "\n",
            "Epoch 33/99\n",
            "----------\n",
            "train Loss: 0.5656 Acc: 0.1210\n",
            "test Loss: 0.2813 Acc: 0.9862\n",
            "\n",
            "Epoch 34/99\n",
            "----------\n",
            "train Loss: 0.5750 Acc: 0.1188\n",
            "test Loss: 0.6119 Acc: 0.7118\n",
            "\n",
            "Epoch 35/99\n",
            "----------\n",
            "train Loss: 0.5837 Acc: 0.1185\n",
            "test Loss: 0.2393 Acc: 0.9868\n",
            "\n",
            "Epoch 36/99\n",
            "----------\n",
            "train Loss: 0.5834 Acc: 0.1188\n",
            "test Loss: 0.4720 Acc: 0.9263\n",
            "\n",
            "Epoch 37/99\n",
            "----------\n",
            "train Loss: 0.5794 Acc: 0.1207\n",
            "test Loss: 0.5662 Acc: 0.7914\n",
            "\n",
            "Epoch 38/99\n",
            "----------\n",
            "train Loss: 0.5780 Acc: 0.1170\n",
            "test Loss: 0.4138 Acc: 0.9595\n",
            "\n",
            "Epoch 39/99\n",
            "----------\n",
            "train Loss: 0.5796 Acc: 0.1193\n",
            "test Loss: 0.4819 Acc: 0.9168\n",
            "\n",
            "Epoch 40/99\n",
            "----------\n",
            "train Loss: 0.5844 Acc: 0.1168\n",
            "test Loss: 0.2605 Acc: 0.9868\n",
            "\n",
            "Epoch 41/99\n",
            "----------\n",
            "train Loss: 0.5756 Acc: 0.1178\n",
            "test Loss: 0.4041 Acc: 0.9707\n",
            "\n",
            "Epoch 42/99\n",
            "----------\n",
            "train Loss: 0.5735 Acc: 0.1193\n",
            "test Loss: 0.4806 Acc: 0.8822\n",
            "\n",
            "Epoch 43/99\n",
            "----------\n",
            "train Loss: 0.5787 Acc: 0.1173\n",
            "test Loss: 0.3273 Acc: 0.9839\n",
            "\n",
            "Epoch 44/99\n",
            "----------\n",
            "train Loss: 0.5740 Acc: 0.1183\n",
            "test Loss: 0.3339 Acc: 0.9839\n",
            "\n",
            "Epoch 45/99\n",
            "----------\n",
            "train Loss: 0.5668 Acc: 0.1178\n",
            "test Loss: 0.4013 Acc: 0.9766\n",
            "\n",
            "Epoch 46/99\n",
            "----------\n",
            "train Loss: 0.5757 Acc: 0.1193\n",
            "test Loss: 0.3323 Acc: 0.9865\n",
            "\n",
            "Epoch 47/99\n",
            "----------\n",
            "train Loss: 0.5757 Acc: 0.1180\n",
            "test Loss: 0.2771 Acc: 0.9865\n",
            "\n",
            "Epoch 48/99\n",
            "----------\n",
            "train Loss: 0.5943 Acc: 0.1170\n",
            "test Loss: 0.3251 Acc: 0.9859\n",
            "\n",
            "Epoch 49/99\n",
            "----------\n",
            "train Loss: 0.5706 Acc: 0.1183\n",
            "test Loss: 0.3610 Acc: 0.9803\n",
            "\n",
            "Epoch 50/99\n",
            "----------\n",
            "train Loss: 0.5788 Acc: 0.1195\n",
            "test Loss: 0.3877 Acc: 0.9819\n",
            "\n",
            "Epoch 51/99\n",
            "----------\n",
            "train Loss: 0.5737 Acc: 0.1195\n",
            "test Loss: 0.2225 Acc: 0.9868\n",
            "\n",
            "Epoch 52/99\n",
            "----------\n",
            "train Loss: 0.5836 Acc: 0.1190\n",
            "test Loss: 0.4322 Acc: 0.9612\n",
            "\n",
            "Epoch 53/99\n",
            "----------\n",
            "train Loss: 0.5753 Acc: 0.1170\n",
            "test Loss: 0.5501 Acc: 0.8487\n",
            "\n",
            "Epoch 54/99\n",
            "----------\n",
            "train Loss: 0.5741 Acc: 0.1190\n",
            "test Loss: 0.2789 Acc: 0.9865\n",
            "\n",
            "Epoch 55/99\n",
            "----------\n",
            "train Loss: 0.5842 Acc: 0.1180\n",
            "test Loss: 0.2676 Acc: 0.9855\n",
            "\n",
            "Epoch 56/99\n",
            "----------\n",
            "train Loss: 0.5736 Acc: 0.1188\n",
            "test Loss: 0.3045 Acc: 0.9832\n",
            "\n",
            "Epoch 57/99\n",
            "----------\n",
            "train Loss: 0.5690 Acc: 0.1207\n",
            "test Loss: 0.2623 Acc: 0.9859\n",
            "\n",
            "Epoch 58/99\n",
            "----------\n",
            "train Loss: 0.5686 Acc: 0.1198\n",
            "test Loss: 0.2322 Acc: 0.9865\n",
            "\n",
            "Epoch 59/99\n",
            "----------\n",
            "train Loss: 0.6061 Acc: 0.1163\n",
            "test Loss: 0.4336 Acc: 0.9507\n",
            "\n",
            "Epoch 60/99\n",
            "----------\n",
            "train Loss: 0.5880 Acc: 0.1198\n",
            "test Loss: 0.3044 Acc: 0.9836\n",
            "\n",
            "Epoch 61/99\n",
            "----------\n",
            "train Loss: 0.5716 Acc: 0.1195\n",
            "test Loss: 0.4263 Acc: 0.9655\n",
            "\n",
            "Epoch 62/99\n",
            "----------\n",
            "train Loss: 0.5769 Acc: 0.1193\n",
            "test Loss: 0.4757 Acc: 0.9187\n",
            "\n",
            "Epoch 63/99\n",
            "----------\n",
            "train Loss: 0.5895 Acc: 0.1190\n",
            "test Loss: 0.4656 Acc: 0.9141\n",
            "\n",
            "Epoch 64/99\n",
            "----------\n",
            "train Loss: 0.5894 Acc: 0.1180\n",
            "test Loss: 0.4237 Acc: 0.9582\n",
            "\n",
            "Epoch 65/99\n",
            "----------\n",
            "train Loss: 0.5886 Acc: 0.1160\n",
            "test Loss: 0.2858 Acc: 0.9868\n",
            "\n",
            "Epoch 66/99\n",
            "----------\n",
            "train Loss: 0.5887 Acc: 0.1202\n",
            "test Loss: 0.3796 Acc: 0.9809\n",
            "\n",
            "Epoch 67/99\n",
            "----------\n",
            "train Loss: 0.5902 Acc: 0.1170\n",
            "test Loss: 0.4088 Acc: 0.9536\n",
            "\n",
            "Epoch 68/99\n",
            "----------\n",
            "train Loss: 0.5897 Acc: 0.1178\n",
            "test Loss: 0.4220 Acc: 0.9671\n",
            "\n",
            "Epoch 69/99\n",
            "----------\n",
            "train Loss: 0.5915 Acc: 0.1183\n",
            "test Loss: 0.3107 Acc: 0.9862\n",
            "\n",
            "Epoch 70/99\n",
            "----------\n",
            "train Loss: 0.5864 Acc: 0.1193\n",
            "test Loss: 0.4167 Acc: 0.9671\n",
            "\n",
            "Epoch 71/99\n",
            "----------\n",
            "train Loss: 0.5874 Acc: 0.1202\n",
            "test Loss: 0.3684 Acc: 0.9816\n",
            "\n",
            "Epoch 72/99\n",
            "----------\n",
            "train Loss: 0.5810 Acc: 0.1185\n",
            "test Loss: 0.2890 Acc: 0.9865\n",
            "\n",
            "Epoch 73/99\n",
            "----------\n",
            "train Loss: 0.5978 Acc: 0.1168\n",
            "test Loss: 0.3991 Acc: 0.9783\n",
            "\n",
            "Epoch 74/99\n",
            "----------\n",
            "train Loss: 0.5836 Acc: 0.1190\n",
            "test Loss: 0.3061 Acc: 0.9845\n",
            "\n",
            "Epoch 75/99\n",
            "----------\n",
            "train Loss: 0.5887 Acc: 0.1190\n",
            "test Loss: 0.4276 Acc: 0.9655\n",
            "\n",
            "Epoch 76/99\n",
            "----------\n",
            "train Loss: 0.5938 Acc: 0.1190\n",
            "test Loss: 0.2427 Acc: 0.9868\n",
            "\n",
            "Epoch 77/99\n",
            "----------\n",
            "train Loss: 0.5883 Acc: 0.1190\n",
            "test Loss: 0.4655 Acc: 0.9368\n",
            "\n",
            "Epoch 78/99\n",
            "----------\n",
            "train Loss: 0.5861 Acc: 0.1212\n",
            "test Loss: 0.2941 Acc: 0.9852\n",
            "\n",
            "Epoch 79/99\n",
            "----------\n",
            "train Loss: 0.6001 Acc: 0.1215\n",
            "test Loss: 0.3217 Acc: 0.9836\n",
            "\n",
            "Epoch 80/99\n",
            "----------\n",
            "train Loss: 0.5889 Acc: 0.1175\n",
            "test Loss: 0.4195 Acc: 0.9720\n",
            "\n",
            "Epoch 81/99\n",
            "----------\n",
            "train Loss: 0.5879 Acc: 0.1183\n",
            "test Loss: 0.6704 Acc: 0.5796\n",
            "\n",
            "Epoch 82/99\n",
            "----------\n",
            "train Loss: 0.5830 Acc: 0.1175\n",
            "test Loss: 0.6403 Acc: 0.6510\n",
            "\n",
            "Epoch 83/99\n",
            "----------\n",
            "train Loss: 0.5919 Acc: 0.1188\n",
            "test Loss: 0.3309 Acc: 0.9812\n",
            "\n",
            "Epoch 84/99\n",
            "----------\n",
            "train Loss: 0.5929 Acc: 0.1202\n",
            "test Loss: 0.2968 Acc: 0.9865\n",
            "\n",
            "Epoch 85/99\n",
            "----------\n",
            "train Loss: 0.5976 Acc: 0.1207\n",
            "test Loss: 0.2833 Acc: 0.9865\n",
            "\n",
            "Epoch 86/99\n",
            "----------\n",
            "train Loss: 0.5861 Acc: 0.1195\n",
            "test Loss: 0.3618 Acc: 0.9793\n",
            "\n",
            "Epoch 87/99\n",
            "----------\n",
            "train Loss: 0.5859 Acc: 0.1190\n",
            "test Loss: 0.4062 Acc: 0.9592\n",
            "\n",
            "Epoch 88/99\n",
            "----------\n",
            "train Loss: 0.5851 Acc: 0.1210\n",
            "test Loss: 0.6116 Acc: 0.7138\n",
            "\n",
            "Epoch 89/99\n",
            "----------\n",
            "train Loss: 0.5799 Acc: 0.1200\n",
            "test Loss: 0.2509 Acc: 0.9865\n",
            "\n",
            "Epoch 90/99\n",
            "----------\n",
            "train Loss: 0.5887 Acc: 0.1160\n",
            "test Loss: 0.4624 Acc: 0.9388\n",
            "\n",
            "Epoch 91/99\n",
            "----------\n",
            "train Loss: 0.5873 Acc: 0.1212\n",
            "test Loss: 0.2932 Acc: 0.9862\n",
            "\n",
            "Epoch 92/99\n",
            "----------\n",
            "train Loss: 0.5888 Acc: 0.1195\n",
            "test Loss: 0.4823 Acc: 0.9336\n",
            "\n",
            "Epoch 93/99\n",
            "----------\n",
            "train Loss: 0.5815 Acc: 0.1205\n",
            "test Loss: 0.4264 Acc: 0.9405\n",
            "\n",
            "Epoch 94/99\n",
            "----------\n",
            "train Loss: 0.5837 Acc: 0.1185\n",
            "test Loss: 0.2972 Acc: 0.9865\n",
            "\n",
            "Epoch 95/99\n",
            "----------\n",
            "train Loss: 0.5941 Acc: 0.1173\n",
            "test Loss: 0.4365 Acc: 0.9572\n",
            "\n",
            "Epoch 96/99\n",
            "----------\n",
            "train Loss: 0.5854 Acc: 0.1175\n",
            "test Loss: 0.3362 Acc: 0.9855\n",
            "\n",
            "Epoch 97/99\n",
            "----------\n",
            "train Loss: 0.5941 Acc: 0.1175\n",
            "test Loss: 0.4381 Acc: 0.9539\n",
            "\n",
            "Epoch 98/99\n",
            "----------\n",
            "train Loss: 0.5859 Acc: 0.1207\n",
            "test Loss: 0.3219 Acc: 0.9845\n",
            "\n",
            "Epoch 99/99\n",
            "----------\n",
            "train Loss: 0.5936 Acc: 0.1180\n",
            "test Loss: 0.2632 Acc: 0.9868\n",
            "\n",
            "Training complete in 179m 8s\n",
            "Best val Acc: 0.986842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr0OoO09Y-1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_ft, './drive/My Drive/covid_vgg_epoch%d_newDataset.pt'%100)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}